{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76184d0d-e287-4583-a002-2827c07f684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import pic\n",
    "import numpy as np\n",
    "from methods.utils import VisionSensitivityN\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "from visualization import HeatmapVisualizer, visualize_original, visualize, visualize_softmax\n",
    "from torchvision.models import efficientnet_b0,resnet50\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_test_dataset, get_dataset\n",
    "from methods import big_pipeline, ig_pipeline\n",
    "from methods import sm_pipeline, ma2norm_b4_softmax_pipeline, ma2norm_after_softmax_pipeline, ma2cos_sign_b4_softmax_pipeline, ma2cos_sign_after_softmax_pipeline, ma2cos_without_sign_b4_softmax_pipeline, ma2cos_without_sign_after_softmax_pipeline, ma2ba_sign_b4_softmax_pipeline, ma2ba_sign_after_softmax_pipeline, ma2ba_without_sign_b4_softmax_pipeline, ma2ba_without_sign_after_softmax_pipeline, dl_pipeline\n",
    "my_font = fm.FontProperties(fname=\"fonts/SimHei.ttf\")\n",
    "mask_viz = HeatmapVisualizer(blur=7, normalization_type=\"signed_max\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from methods.utils import VisionInsertionDeletion\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(3407)\n",
    "mean = np.array((0.485, 0.456, 0.406))\n",
    "std = np.array((0.229, 0.224, 0.225))\n",
    "import pickle\n",
    "# import pickle\n",
    "with open(\"attribution_map_ma2ba_without_sign_after_softmax_resnet50.pkl\",\"rb\") as f:\n",
    "    attribution_map_ma2ba_without_sign_after_softmax = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a87a0-dc20-426c-94a7-934f7f267344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_curve_xy(x, y, title='PIC', label=None, color='blue',\n",
    "    ax=None):\n",
    "  if ax is None:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "  auc = np.trapz(y) / y.size\n",
    "  label = f'{label}, AUC={auc:.3f}'\n",
    "  ax.plot(x, y, label=label, color=color)\n",
    "  ax.set_title(title)\n",
    "  ax.set_xlim([0.0, 1.0])\n",
    "  ax.set_ylim([0.0, 1.0])\n",
    "  ax.legend()\n",
    "\n",
    "\n",
    "def show_curve(compute_pic_metric_result, title='PIC', label=None, color='blue',\n",
    "    ax=None):\n",
    "  show_curve_xy(compute_pic_metric_result.curve_x,\n",
    "                compute_pic_metric_result.curve_y, title=title, label=label,\n",
    "                color=color,\n",
    "                ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0de866-0799-4db3-a1d2-7955a57338a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader, data_min, data_max = get_dataset(\"imagenet\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2ed20-12e5-4aae-a465-5736a2130d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97dc7dc-52e8-4069-9264-13f3f7d7508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_insertion_deletion = VisionInsertionDeletion(model,pixel_batch_size=128,sigma=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7efc481-eda9-4062-89f5-16a281031c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vid(attribution_map):\n",
    "    data = attribution_map[0]\n",
    "    label = attribution_map[1]\n",
    "    attribution = attribution_map[2]\n",
    "    attribution = np.array(attribution)\n",
    "    data = np.array(data)\n",
    "    if len(attribution.shape) == 3:\n",
    "        attribution = attribution[np.newaxis, ...]\n",
    "    if len(data.shape) == 3:\n",
    "        data = data[np.newaxis, ...]\n",
    "    im_, mask = mask_viz(attribution, data, overlay_opacity=0.5,\n",
    "                         imshow=False, return_tiled=True)\n",
    "    mask = (mask - mask.min()) / (mask.max() - mask.min()+1e-10)\n",
    "    vid = (vision_insertion_deletion.evaluate(heatmap=torch.from_numpy(mask).to(device), input_tensor=torch.from_numpy(\n",
    "        data.squeeze()).to(device), target=torch.from_numpy(np.array(label)).to(device)))\n",
    "    return vid['ins_auc'],vid['del_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6107d23-1946-4d5e-87b4-a157eb807a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vid_parallel(attribution,num_workers=8):\n",
    "    data = attribution[\"data\"] # list\n",
    "    target = attribution[\"label\"] # list\n",
    "    attribution = attribution[\"attribution\"] # list\n",
    "    # pool = ThreadPool(num_workers)\n",
    "    # results = pool.map(get_vid,list(zip(data,target,attribution)))\n",
    "    # pool.close()\n",
    "    # pool.join()\n",
    "    dt = list(zip(data,target,attribution))\n",
    "    results = []\n",
    "    for d in tqdm(dt):\n",
    "        results.append(get_vid(d))\n",
    "    results = np.array(results)\n",
    "    print(\"ins_auc\",results[:,0].mean())\n",
    "    print(\"del_auc\",results[:,1].mean())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025ec0e-e5e8-4000-ad65-6f67314d885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=200) as pbar:\n",
    "    calculate_vid_parallel(attribution_map_ma2ba_without_sign_after_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18b09d-5d11-446b-804a-f8aa4b84a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prediction function.\n",
    "def create_predict_function_softmax(class_idx):\n",
    "  \"\"\"Creates the model prediction function that can be passed to compute_pic_metric method.\n",
    "\n",
    "    The function returns the softmax value for the Softmax Information Curve.\n",
    "  Args:\n",
    "    class_idx: the index of the class for which the model prediction should\n",
    "      be returned.\n",
    "  \"\"\"\n",
    "\n",
    "  def predict(image_batch):\n",
    "    \"\"\"Returns model prediction for a batch of images.\n",
    "\n",
    "    The method receives a batch of images in uint8 format. The method is responsible to\n",
    "    convert the batch to whatever format required by the model. In this particular\n",
    "    implementation the conversion is achieved by calling preprocess_input().\n",
    "\n",
    "    Args:\n",
    "      image_batch: batch of images of dimension [B, H, W, C].\n",
    "\n",
    "    Returns:\n",
    "      Predictions of dimension [B].\n",
    "    \"\"\"\n",
    "    # print(image_batch)\n",
    "    image_batch = image_batch / 255\n",
    "    image_batch -= mean\n",
    "    image_batch /= std\n",
    "    # print(image_batch.shape)\n",
    "    image_batch = image_batch.transpose(0,3,1,2)\n",
    "    image_batch = torch.from_numpy(image_batch).float().to(device)    \n",
    "    score = model(image_batch)[:, class_idx]\n",
    "    return score.cpu().detach().numpy()\n",
    "\n",
    "  return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363463e-2f3f-4376-8760-f6f8662fb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "def process_data_(data, target, attribution):\n",
    "    set_seed(3407)\n",
    "    img = data\n",
    "    std = np.array((0.229, 0.224, 0.225))\n",
    "    mean = np.array((0.485, 0.456, 0.406))\n",
    "    img = ((img.transpose(1,2,0) * std + mean) * 255).astype(np.uint8)\n",
    "    tgt = target\n",
    "    attribution_map = attribution\n",
    "    attribution_map = np.abs(np.sum(attribution_map, axis=0))\n",
    "    saliency_thresholds = [0.5,0.75]\n",
    "    random_mask = pic.generate_random_mask(image_height=img.shape[0],\n",
    "                                   image_width=img.shape[1],\n",
    "                                   fraction=0.01)\n",
    "    pred_func_sic = create_predict_function_softmax(tgt)\n",
    "    try:\n",
    "        result_sic = pic.compute_pic_metric(img=img,\n",
    "                                            saliency_map=attribution_map,\n",
    "                                            random_mask=random_mask,\n",
    "                                            pred_func=pred_func_sic,\n",
    "                                            min_pred_value=0.5,\n",
    "                                            saliency_thresholds=saliency_thresholds,\n",
    "                                            keep_monotonous=True,\n",
    "                                            num_data_points=1000)\n",
    "    except:\n",
    "        return 0\n",
    "    pbar.update()\n",
    "    return result_sic.auc\n",
    "\n",
    "def process_data(data):\n",
    "    return process_data_(data[0],data[1],data[2])\n",
    "\n",
    "def calculate_auc_parallel(attribution,num_workers=8):\n",
    "    data = attribution[\"data\"] # list\n",
    "    target = attribution[\"label\"] # list\n",
    "    attribution = attribution[\"attribution\"] # list\n",
    "    pool = ThreadPool(num_workers)\n",
    "    results = pool.map(process_data,list(zip(data,target,attribution)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509dfb40-28b9-4304-914f-a66e7d8d8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=200) as pbar:\n",
    "    results_ma2ba_without_sign_after_softmax = calculate_auc_parallel(attribution_map_ma2ba_without_sign_after_softmax)\n",
    "np.sum(results_ma2ba_without_sign_after_softmax) / 200"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
